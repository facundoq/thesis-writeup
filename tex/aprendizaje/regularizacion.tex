Como ya se mencionó, hacer un experimento de clasificación involucra estimar el error de $f$ en $\ddp$ usando $D$. Para eso divide $D$ en $\cdp$ y $\cde$, y se mide el error en $\cdp$. Si dicho error es aceptable, se considera que el clasificador es adecuado para la tarea. Ahora bien, si el error es muy grande puede ser que el clasificador no sea adecuado para la tarea, no se haya entrenado lo suficiente, o los datos sean insuficientes o de mala calidad. Si además se mide el error de $f$ en $\cde$ y también es alto, se obtiene una confirmación de ello. Pero si $f$ se comporta bien con $\cde$, existe otra razón posible: el clasificador se adaptó tanto a los ejemplares de $\cde$ que no puede generalizar cuando se presentan los de $\cdp$.

Entonces, si un clasificador se especializa tanto en el conjunto de ejemplares con el cual fue entrenado que pierde o no adquiere la capacidad de generalizar, es decir, clasificar correctamente ejemplares no vistos, ejemplares de $\ddp$ en general, se dice que sufre del fenómeno de \textbf{overfitting} (sobre-especialización) que se da cuando un clasificador tiene un nivel de error significativamente menor en el conjunto de entrenamiento que en nuevos ejemplares del problema. Esto puede suceder cuando un clasificador se entrena de forma excesiva o utilizando métodos que no se adaptan bien al dominio del problema.

\tikzimage{error_vs_entrenamiento}{scale=0.7}{Curvas típicas de: $\rl(D_e,f)$ y $\rl(\ddp,f)$ en función de la cantidad de iteraciones de entrenamiento o fuerza del ajuste de $f$ con $D$. El error se puede decrementar arbitrariamente para el conjunto de entrenamiento, pero llega un momento donde el entrenamiento extra incrementa el error sobre el dominio del problema $\ddp$. }

En este sentido, si bien es importante entrenar un clasificador adecuadamente para minimizar el error en $\cde$, un entrenamiento que ajuste $f$ demasiado a $\cde$ traerá un error mayor en $\cdp$. 

\tikzimagetwo{outlier_razonable}{scale=0.2}{ Conjunto de datos $D$ con dos clases, donde hay un outlier. Si bien el hiperplano no clasifica correctamente todos los ejemplares, provee una separación coherente entre clases.}
{outlier_no_razonable}{scale=0.2}{Mismo $D$, con un hiperplano sobre-entrenado: clasifica bien todas las instancias de $D$ pero no refleja la distribución real de las clases.}

\tikzimage{outlier_ambos_nuevo_ejemplar}{scale=0.25}{Comportamiento de ambos clasificadores ante un nuevo ejemplar.}

El problema del overfitting también se da, en ocasiones, cuando la potencia del clasificador utilizado excede la necesaria para resolver un problema dado. En este caso, puede que el mismo se ajuste tan bien a los datos de entrenamiento que no pueda lidiar con desviaciones mayores de los mismos, como se muestra en la figura.


\tikzimagetwo
{potencia_clasificador}{scale=0.8}{ Distribución real de ejemplares por clases}
{potencia_clasificador_overfitting}{scale=0.8}{Distribución aprendida por el clasificador. Las regiones de Voronoi se ajustan tan perfectamente a cada ejemplar que no consideran el espacio entre ejemplares de una clase como de la misma clase.}


En ocasiones, lo que se necesita es limitar el poder del clasificador. En la figura anterior, se consideró el poder computacional del clasificador como bastante alto ya que debe de alguna manera recordar o incluir en su modelo todos los ejemplares usados para el entrenamiento de forma bastante específica. Si se limita la cantidad de ejemplares a recordar en el clasificador en el caso anterior, se podría obtener una clasificación mejor:

\tikzimage
{potencia_clasificador_simple}{scale=0.8}{ Distribución aprendida por el clasificador con capacidad limitada. Hay menos regiones de Voronoi que en el primer caso, pero son más grandes y menos específicas, obteniendo una clasificación más acertada.}

En este caso se puede considerar la cantidad de ejemplares en los que basarse como un parámetro del modelo. Este método de limitación del poder computacional se conoce como un esquema de \textbf{regularización}, y sigue el principio de la navaja de Occam: si dos modelos explican un fenómeno, por principio se elige el más simple de los dos. Dicho esquema puede estar basado en la selección de algún parámetro del entrenamiento del clasificador, o puede estar incluido directamente mediante un proceso de entrenamiento que penalice clasificadores complejos en preferencia de los más simples. En el último caso, el esquema general para entrenar un clasificador podría ser:

\begin{equation*}
\begin{aligned}
\underset{f=g(\cde)}{\text{Minimizar}} & & error(f,\cde) + complejidad(f) 
\end{aligned}
\end{equation*}

Donde $complejidad$ es alguna función que mide la complejidad de $f$, dependiente del algoritmo de entrenamiento del clasificador utilizado. Se verán ejemplos de esquemas de regularización cuando se desarrolle el modelo SVM y los algoritmos de entrenamiento para redes feedforward en los capítulos siguientes.

En otros casos, cambiar a un modelo de clasificador más simple que se adapte mejor al problema puede solucionar el problema.

\tikzimage{potencia_clasificador_hiperplanos}{scale=0.8}{Distribución aprendida por un clasificador basado en hiperplanos.}

De todas maneras, el clasificador con hiperplanos gana simplicidad porque implícitamente está haciendo una hipótesis (fuerte) de que la mitad de $\reals^2$ pertenece a una clase, y la otra mitad a otra; es decir, para todo punto en el espacio de ejemplares, hay una clase correspondiente. El modelo de hiperesferas, por otro lado, sólo asigna una clase a los puntos cercanos a los conocidos durante el entrenamiento.
