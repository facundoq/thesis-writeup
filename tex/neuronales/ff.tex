

El modelo feedforward (FF) extiende el perceptrón introduciendo el concepto de capas de neuronas (de entrada, ocultas y de salida), funciones de cada neurona no-lineales, y la utilización de varias neuronas de salida para codificar el resultado de la red. Es uno de los modelos más populares de red neuronal, uno de los que popularizó la técnica.

\tikzimage{feedforward}{scale=0.5}{Una red feedforward con tres capas: la primera, de entrada, luego un capa oculta, y finalmente una capa de salida, con varias neuronas de salida. Las funciones de las neuronas pueden ser no-lineales.} 

Se mostrará el modelo feedforward en tres pasos, introduciendo tres problemas que motivan cambios en la formulación del perceptrón para llegar al modelo deseado.

\subsection{Varias clases}

Supónganse que se busca clasificar $C$ clases de ejemplares. Se puede representar la existencia de varias clases utilizando $C$ neuronas de salida como las del perceptrón, una por cada clase. Habrá entonces $C$ hiperplanos de separación que entrenar, cada uno con sus parámetros. 


\tikzimagetwo{ff_2entradas_2salidas}{scale=0.7}{Una red neuronal con 2 neuronas de entrada y 3 de salida.}{clases3_hiperplanos3}{scale=0.22}{Ejemplares de tres clases distintas. Cada grupo de ejemplares está separado del resto por un hiperplano.}

Se interpreta la salida de esta red como un vector $\ov$, donde $o_c$ es el resultado calculado para la neurona de salida $c$. En este caso, un vector de la clase $c$ está bien clasificado si $o_c=1$ y $o_j=-1, j \neq c$. Se puede entrenar esta red aplicando el algoritmo del perceptrón a cada neurona $c$ por separado. 


Se puede ver la topología de la red como dos capas de neuronas, las de entrada y las de salida. A continuación, se generaliza la noción de capas en las redes considerando el problema de la clasificación de los ejemplares de una clase $c$ contra los del resto de las clases.

\subsection{Capas ocultas}

Supóngase que se busca clasificar ejemplares de las 3 clases:  

\tikzimage{clases3_no_separables}{scale=0.3}{Ejemplares de tres clases distintas. La clase 2 no puede separarse del resto con un solo hiperplano.
}

Se ve claramente que no existe un hiperplano que pueda separar la clase 2 (triángulo) del resto de las clases. 

El perceptrón multiclase no puede solucionar este problema, pero quizás realizando una transformación del espacio de ejemplares se pueda volver a un problema tratable. Es fácil observar que se puede separar a la clase 2 del resto utilizando \textit{dos} hiperplanos, entre la clase 1 y la 2, y la 2 y la 3.


\tikzimage{clases3_no_separables_hiperplanos}{scale=0.3}{Ejemplares de tres clases distintas; los hiperplanos separan a la clase 2 del resto.
}

El resultado es entonces un dominio $\ddp$ particionado por regiones de voronoi ligeramente más complejas que con el simple perceptrón, y por ende más potentes para su clasificación.

Se puede implementar este concepto introduciendo una nueva capa de neuronas \textit{ocultas} entre la capa de entrada y la de salida. El propósito de esta capa es transformar los ejemplares a una representación más simple para clasificar, manteniendo el mismo tipo y cantidad de neuronas en la capa de salida que antes. 

\tikzimage{ff_2entradas_2ocultas_3salidas}{scale=0.7}{Un perceptrón multiclase con una capa oculta de dos neuronas.}

En el ejemplo, se puede utilizar una capa oculta con dos neuronas que representen los hiperplanos de la figura Y.

De esta forma, asumiendo que los vectores normales a los hiperplanos están orientados hacia la derecha, los ejemplares de la clase 1 se convierten en un vector $(x,y)$, donde $(x,y)=(-1,-1)$; para los de la clase 2, $(x,y)=(1,-1)$; y para los de la clase 3, $(x,y)=(1,1)$. 


\tikzimage{2ocultas_3clases_transformacion}{scale=1}{Transformación de las neuronas de entrada a las neuronas ocultas.}

De esta forma, la transformación pone a los ejemplares de cada clase de forma tal que puedan ser clasificados con una capa de salida como la de antes.

En la práctica, por simplicidad se suele asignar a todas las neuronas de una misma capa la misma función, aunque con distintos parámetros. Se pueden utilizar varias capas ocultas, una a continuación de la otra, para lograr una transformación más compleja. 

El entrenamiento de una red con estas características requiere minimizar respecto a los parámetros de las funciones de las neuronas ocultas y las neuronas de salida al mismo tiempo, con lo cual el algoritmo clásico de entrenamiento del perceptrón no puede aplicarse. Para entrenar esta red, se puede utilizar el algoritmo backpropagation, a describirse luego. Antes, se introducirá la necesidad de emplear funciones no lineales en las neuronas para resolver problemas más complejos.

\subsection{Funciones no lineales}

Hasta ahora se han utilizado funciones lineales para definir superficies de separación que permiten clasificar los ejemplares. 

A las funciones $o_i$ de las neuronas se las suele definir como la composición de una \textbf{función de combinación} $\fdef{h_i}{\reals^{n_i}}{\reals}$ y una \textbf{función de activación o transferencia} $\fdef{\theta_i}{\reals}{\reals}$. La primera combina de alguna manera los estímulos entrantes a un solo número; la segunda aplica una transformación a ese número. 

En el ejemplo del perceptrón, la función de combinación es $h$ y la de activación $\theta$. La función de combinación separa el espacio en dos hiperplanos; la de activación asigna la etiqueta $1$ a los ejemplares que quedan a un lado del hiperplano y $-1$ a los otros. 

Supóngase un problema de dos clases, en donde las mismas no pueden separarse fácilmente por un clasificador lineal, ni siquiera uno de dos capas. 

\tikzimage{ff_no_lineal_clases2_ojo}{scale=0.3}{Dos clases que no son linealmente separables}

Se debe buscar una superficie de separación de las clases que sea no lineal, y eso implica introducir funciones no lineales en las neuronas.

Dado que la clase 1 es un círculo limitado por la clase 2, se puede definir una función:
\ma{ 
o(\xv)= \theta_t(c(\xv)) \\
c(\xv)= \norm{\xv-\ve{c}}-r
}

que representa la pertenencia de un ejemplar a un círculo con centro $\ve{c}$ y radio $r$. Optimizando el error respecto a estos parámetros, de manera que el círculo esté centrado en el centro de masa de la clase 1 y tenga un radio igual a la dispersión de los ejemplares de esa clase, se obtendrá un clasificador cuya salida es 1 para los ejemplares dentro del círculo y 0 para los otros.  


\tikzimage{ff_no_lineal_clases2_ojo_clase}{scale=0.3}{Un separador basado en hiperesferas puede separar las dos clases.}

De esta manera, cambiando la función de combinación a una que mide la distancia de los ejemplares al borde del círculo, se obtuvo una transformación a un espacio donde los ejemplares son separables.

Es importante notar que en el caso de utilizar una red con una capa oculta y funciones lineales, la función total que la red computa es \textit{no lineal}, ya que es la composición de varias funciones lineales. Agregando capas ocultas se puede complejizar la transformación de los ejemplares, haciendo aún más no lineal el comportamiento de la red. 

\subsubsection{Funciones de activación usuales}

La capacidad de una red está definida en gran parte por sus funciones. En la práctica la función de combinación suele ser la lineal, ya que los hiperplanos son buenos como separadores de primera línea, debido a que particionan el espacio \textit{grosso modo}. En el caso más simple, se puede utilizar la función de activación $\theta_t$, que modela un hiperplano lineal de separación. Si bien esta función es útil, tiene la desventaja de que es muy simple y no es diferenciable en el origen, requisito necesario para utilizar la mayoría de los algoritmos de entrenamiento, como backpropagation.

Dentro de las funciones no lineales, las funciones polinómicas como $x^p$ son útiles en ciertos casos, pero tienen dos problemas principales:

\begin{itemize}
\item Suelen ser poco representativas como funciones de la capa de salida, ya que su imagen es $\reals$ y hacen difícil codificar clases en la capa de salida.
\item Su utilización en las capas ocultas puede hacer que los estímulos de la red se hagan arbitrariamente grandes o pequeños, haciendo muy difícil el entrenamiento de la misma, ya que algunas neuronas tendrán tanta señal que \textit{taparán} los estímulos de las otras.
\end{itemize} 

Entonces, en la práctica se suelen utilizar funciones no lineales de activación que sean \textbf{sigmoideas}. Las funciones sigmoideas se caracterizan por tener dos asíntotas horizontales que limitan los valores de la función por arriba y por debajo, de manera que saturen en dos valores, típicamente $0$ y $1$ o $-1$ y $1$ \cite{lecun1998}. Las sigmoideas más utilizadas son la función logística $S$ y la tangente hiperbólica $tanh$:

\newcommand{\logistic}{\frac{1}{1+ e^{-x}}}
\newcommand{\tanhdef}{\frac{sinh(x)}{cosh(x)}}

\ma{
S(x) &= \logistic & tanh(x)&= \tanhdef
}

\tikzimagetwo{logistic}{scale=0.4}{La función logística $S(x) = \logistic$.}{tanh}{scale=0.4}{La tangente hiperbólica $tanh(x)= \tanhdef$. 
}

Las funciones $S$ y $tanh$ tienen asíntotas horizontales en $0$ y $1$, y $-1$ y $1$, respectivamente. Las dos funciones están relacionadas por $ tanh(x)= 2 S(2x) -1$; entonces, $tanh$ es una versión escalada de $S$, o viceversa. 

La diferencia fundamental entre las dos es que $tanh$ suele funcionar mejor en las capas ocultas, ya que su imagen es $(-1,1)$, con lo cual tiene la ventaja de cruzar el $0$ y ser simétrica respecto al eje $x$, lo cual puede acelerar el aprendizaje ya que evita que se saturen rápidamente los valores por ser todos positivos, como en el caso de la función logística. En otras palabras, las salidas de las neuronas suman y restan, con lo cual una red aleatoria tenderá más a tener salidas centradas en 0, mientras que una red aleatoria con funciones logísticas tiende a saturarse en 1.

La logística tiene una imagen que puede ser interpretada como una confianza, haciéndola útil para la capa de salida. Se utiliza el término confianza y no probabilidad, ya que nada asegura que el valor de las neuronas de salida represente una distribución de probabilidad.

Para ello, a veces se agrega una capa de salida con funciones llamadas \textbf{softmax} que normalizan el valor de las neuronas de salida de manera que su suma sea 1 y puedan funcionar mejor como estimaciones de probabilidad. Si hay $L$ neuronas con funciones en la capa de salida original, con valor $o_i$, se agregan $L$ neuronas softmax con valor:

\ma{
o_i^{sm}= \frac{o_i}{\sumj o_j}
}


Las neuronas de la capa de salida original pueden tener funciones de activación logísticas u otras.

Entonces, si se utilizan funciones logísticas, por ejemplo, y hay $C$ clases, la capa de salida tiene $C$ elementos y la clase $c$ se puede codificar con el vector $\yv$ tal que $y_c=1$ e $y_j=0, \; j \neq c$. La salida de la red será ahora una función continua, 

La elección de las funciones a utilizar depende fuertemente del dominio del problema particular a resolver, así como de la capacidad de cálculo disponible, y la topología elegida para la red.


\subsubsection{El modelo feedforward}

Combinando estas tres ideas, se puede definir el modelo feedforward como una red acíclica con $L+1$ capas, donde la capa $0$, la primera, es una capa de entrada, las siguientes son capas ocultas ($1,\dots,L-1$), y la última, la $L$, es la capa de salida. Las neuronas de la capa $j$ solo se conectan con las de la capa $j+1$, exceptuando las de la capa de salida que no tienen conexiones salientes. Cada capa puede tener un número distinto de neuronas $n_j$. 

Las funciones de cada neurona son una composición de una función de combinación $\fdef{c_i}{\reals^n}{\reals}$ y una función de activación $\fdef{\theta_i}{\reals}{\reals}$, de naturaleza lineal o no lineal. Cada función tiene parámetros que en el proceso de entrenamiento deben modificarse con el objetivo de minimizar el error en la red. 

En el modelo feedforward, generalmente se realizan otras dos simplificaciones respecto del modelo general de redes neuronales:

\begin{itemize}
\item Se utilizará la misma familia de funciones en todas las neuronas de una misma capa, aunque cada neurona tendrá sus propios parámetros para su función. 

\item La función de combinación será lineal, es decir $c(\xv)= \wv \cdot \xv$.
\end{itemize}


\tikzimage{feedforward_combinacion_activacion}{scale=0.5}{Una red feedforward con 3 capas.}


Se hará referencia a la salida de la neurona $i$ de la capa $j$ como $o_i^j$. 
La capa de entrada será la $0$, con $n_0=d$ neuronas, y entonces los valores salida de dicha capa son $\ovz=(o_1^0,\dots,o_d^0)$. Las neuronas de la capa de entrada no tienen ninguna función (o utilizan la función identidad), y entonces al ser estimulada con un ejemplar $\xv$, los valores de sus neuronas son $\ovz=\xv$.

Existe una función de activación $\theta^j$ para las neuronas de las otras capas ($j>0$). Además, para la neurona $i$ de la capa $j>0$, hay un vector de coeficientes del hiperplano de la función de combinación, $\wvij \in \reals^{n_{j-1}}$. Entonces, para cada capa $j>0$ existe una matriz de coeficientes $\Wj \in \reals^{n_j \times n_{j-1}}$, compuesta por filas $\wv_1^j,\dots,\wv_{n_j}^j$  los cuales \textit{pesan} las salidas de las neuronas de la capa $j-1$. Dicho de otra manera, $\wv_i^j$ tiene los pesos de los arcos que llegan a la neurona $i$ de la capa $j$.

De esta manera, si $\wvij(k)$ es el componente $k$ del vector de pesos $\wvij$, la salida de la neurona $i$ de la capa $j$, $\oij$, puede expresarse como:

\ma{
\oij &= \actj(\netij) \\
\netij &= \sum_{k=1}^{n_{j-1}} o_k^{j-1} \wvij(k) =  \ovjmu \cdot \wvij 
}

En esta expresión, $\netij$ se conoce como la entrada neta a la neurona $i$ de la capa $j$, asumiendo que el escalado de las salidas de las neuronas de la capa anterior por los pesos $\wvij$ se hace antes de que el estímulo llegue a la neurona, en la sinapsis. 


En una red de dos capas, una de entrada y una de salida, para la neurona de salida $i$ (capa $1$), la expresión es:

\ma{
o_i^1 &= \theta_1(net_i^1) \\
&= \theta_1(\ov^0 \cdot \wv_i^1) \\ 
&= \theta_1(\xv \cdot \wv_i^1) 
}

En una red de tres capas, una de entrada, una oculta y una de salida, para la neurona de salida $i$ (capa $2$), la expresión se expande a:

\ma{
o_i^2 &= \theta_2(net_i^2) \\
&= \theta_2(\ov^1 \cdot \wv_i^2) \\ 
&= \theta_2(  [\theta_1(net_1^1),\dots,\theta_1(net_{n_1}^1)] \cdot \wv_i^2) \\
&= \theta_2(  [\theta_1(\ov^0 \cdot \wv_1^1),\dots,\theta_1(\ov^0 \cdot \wv_{n_1}^{1})] \cdot \wv_i^2) \\
&= \theta_2(  [\theta_1(\xv \cdot \wv_1^1),\dots,\theta_1(\xv \cdot \wv_{n_1}^{1})] \cdot \wv_i^2) \\
}

\tikzimage{feedforward_tres_capas_full}{scale=0.5}{Una red feedforward con 3 capas, donde ahora se muestra la estructura recurrente de los cálculos de cada $\oij$.}


Este modelo tiene, a priori, tantos parámetros como pesos $\wvijk{k}$ haya. Puede que tenga más parámetros, por algunas de las funciones $\theta_j$. El objetivo de un algoritmo de entrenamiento será optimizar el error de la red respecto a estos parámetros.

Habiendo descripto el modelo, se explica ahora el algoritmo backpropagation para entrenar la red, y luego una de sus mejoras, el resilient backpropagation.

\subsection{Algoritmo de entrenamiento Backpropagation}


La idea esencial del backpropagation es recorrer el espacio de parámetros de la red utilizando el opuesto del gradiente del error como indicador de la dirección a tomar para minimizarlo, una técnica conocida como \textbf{descenso de gradiente}.

Dada una red neuronal con $L+1$ capas  y un ejemplar $\xi$, la salida de la red es $\ov^L(\xi)$. Si la clase asociada al ejemplar es $\yi$, donde ahora $\yi=(y_1,\dots,y_C)$ es un vector que señala la pertenencia del ejemplar a cada clase, se puede definir el error cuadrático la red sobre un conjunto de datos $D$ como\footnote{Se incluye la constante $\frac{1}{2}$ para simplificar la derivada de $E(\xv)$.}:

\ma{
E&=\sum_{\xi \in D} E(\xi) \\
E(\xv) &= \sum_{l=1}^C (o^k_l - y_l)^2
}


Donde en la expresión $E_{\xv}$ se asume que $o^L_l$ es la salida de la neurona $l$ de la capa de salida para el ejemplar $\xi$ e $y_l$ es la salida esperada de la neurona $l$ \footnote{Si bien es poco claro que $E(\xv)$ depende de un ejemplar en particular viendo solamente su definición, se realiza esta simplificación ya que de lo contrario la notación debe incluir la capa y número de la neurona de cuyo valor se está hablando, y además el ejemplar que produjo el estímulo inicial para generar dicho valor.}. 

Entonces, dada una topología y una función de activación para cada capa, si los parámetros son $\av$, el objetivo del entrenamiento es:

\optma{&  \minarg{\av}
\quad  E(\av)= \sum_{\xi \in D} E_{\xi} 
}

En este caso, si se utilizan funciones de activación sin parámetros en una red de $L+1$ capas, los parámetros estarán dados por las matrices de pesos de cada capa $\av=\{\W^1,\dots,\W^L\}$, y el problema definitivo es:


\optma{&  \minarg{ \{ \W^1,\dots,\W^L \} }
& & E(\W^1,\dots,\W^L)=\sum_{\xi \in D} E_{\xi}
}

La dirección en el espacio de parámetros en la cual $E$ se incrementa está dada por:

\ma{
\derivative{E}{\W^1}, \dots, \derivative{E}{\W^L}
}

Por ende, el opuesto de esta dirección indica la dirección en la cual $E$ decrece, y siguiendo esta dirección se puede minimizarla. Esto induce a una regla de actualización para mejorar la solución actual del tipo:

\ma{
\W^j \ass \W^j -  \alpha \derivative{E}{\W^j}
}

Donde $\alpha$ es una tasa de aprendizaje que se puede utilizar para regular la magnitud de los cambios. Esta regla permite que el vector $\W^j$ se mueva en el espacio de parámetros en la dirección en que el error decrece. 

El algoritmo de entrenamiento utiliza este hecho para, de forma similar al Perceptrón, modificar iterativamente los pesos de la red hasta que el error de la misma sea lo suficientemente bajo:

\begin{algorithm}[H]
\KwData{ \\
Una toplogía dada por $L+1$, el número de capas, y $n_i$ la cantidad de neuronas de la capa $i$, con $n_L=C$.\\
Un conjunto de ejemplares $\xi \in D$, con $D \subset \reals^d$, y clase $\yi \in \reals^{C}$.\\
Una tolerancia al error $\epsilon$.\\
Una tasa de aprendizaje $\alpha$.}
\KwResult{ Pesos $\W^j$ de las neuronas de cada capa $j>0$, optimizados para clasificar $D$ con un error menor a $\epsilon$ }
\For{j=1 to L}{
	$\W^1=random(n_j,n_{j-1})$\;
}
$error=\infty$ \;
\While{$error > \epsilon$}{	
	\For{j=1 to L}{
		$\dW^j=\derivative{E}{\W^j}$\;
	}
	\For{j=1 to L}{
		$\W_j = \W_j - \alpha \dW_j$ \;
	}
  $error = E(\W^1,\dots,\W^L)$ \;
}
Retornar  $\W^1,\dots,W^L$ \;
\caption{Esquema del algoritmo Backpropagation para una red de tres capas.} 
\end{algorithm}
\vspace{10pt}


Con la presentación de este algoritmo clásico para entrenar redes neuronales feedforward finaliza la descripción de dichas redes. Para el lector interesado, el apéndice \ref{apendice_neuronales} presenta de forma didáctica la derivación de la forma concreta de la regla de actualización para una red neuronal feedforward genérica. Dicho apéndice también menciona algunos problemas comunes en la aplicación efectiva del Backpropagation, e introduce el Resilient Backpropagation para mitigar algunos de ellos. La aplicación del algoritmo Resilient Backpropagation fue necesaria en esta tesina para lograr un nivel de error en el reconocimiento de gestos aceptable con redes feedforward.  
